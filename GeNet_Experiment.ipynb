{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GeNet Experiments Code"
      ],
      "metadata": {
        "id": "tArTx_xNhta7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz4F0o8FTKNx"
      },
      "outputs": [],
      "source": [
        "! pip install tiktoken\n",
        "! pip install cohere\n",
        "! pip install docx\n",
        "! pip install exceptions\n",
        "! pip install python-docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcDgaLxh6eyk"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install openai==1.55.3 httpx==0.27.2 --force-reinstall --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pxe2IDv6hY5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "restart runtime after the cell above (in order to solve openAI API issues (as of date Dec 2024) )"
      ],
      "metadata": {
        "id": "hhOSRQVu0sxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/networkcopilot/GeNet-Framework.git"
      ],
      "metadata": {
        "id": "BaF1DzalpDhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcB17j0zFU16"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('api_key')\n",
        "client = OpenAI(api_key = api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1RnFl-ga9vC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(\"/content/GeNet_Experiment_Results\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmTVc-hUG6EK"
      },
      "outputs": [],
      "source": [
        "run_number = 1 # <--this should change according to your itteration number"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLA_azg9Vbcw"
      },
      "source": [
        "## Topology Understanding using GPT4Turbo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJDv6x4mVgeX"
      },
      "source": [
        "**The prompt for this task:**\n",
        ">  As a network topology analyst, provide a detailed description of the components and edges in the given diagram.\n",
        "Ensure the description includes: (1) the specific icon of each component (if icons are present), such as router, pc, firewall, etc. (2) a detailed list of all edges with both edge interfaces described if edge labels are present.\n",
        "Avoid adding any extra comments or interpretations about the diagram.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om_YtfkEV8Si"
      },
      "source": [
        "### GPT4V request code\n",
        "**NOTICE!** The given image **MUST** be in jpeg format for it to work correctly!\n",
        "\n",
        "as you can see the url of the given image in this code is in a jpeg format - this does effect the correctness of the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaktJ1UuWFLP"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import requests\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('api_key')#need to add the key to the 'secrets section'\n",
        "# OpenAI API Key\n",
        "# Function to encode the image\n",
        "def encode_image(image_path):\n",
        "  with open(image_path, \"rb\") as image_file:\n",
        "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "\n",
        "# Getting the base64 string\n",
        "\n",
        "headers = {\n",
        "  \"Content-Type\": \"application/json\",\n",
        "  \"Authorization\": f\"Bearer {api_key}\"\n",
        "}\n",
        "\n",
        "def create_image_content(_image_path):\n",
        "    return {\n",
        "          \"type\": \"image_url\",\n",
        "          \"image_url\": {\n",
        "            \"url\": f\"data:image/jpeg;base64,{encode_image(_image_path)}\",\n",
        "            \"detail\": \"high\"\n",
        "          }\n",
        "        }\n",
        "def make_request(model_name, input_text, temperature, image_content, image_path=None, max_tokens=300):\n",
        "  content = [\n",
        "        {\n",
        "          \"type\": \"text\",\n",
        "          \"text\": input_text\n",
        "        }]\n",
        "\n",
        "  content.append(image_content)\n",
        "  payload = {\n",
        "    \"model\": model_name,\n",
        "    \"messages\": [\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": content\n",
        "\n",
        "      }\n",
        "    ],\n",
        "    \"max_tokens\": max_tokens,\n",
        "    \"temperature\": temperature,\n",
        "    \"top_p\": 0.1\n",
        "  }\n",
        "\n",
        "  return requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NN2oZSTm4gOW"
      },
      "outputs": [],
      "source": [
        "from inspect import EndOfBlock\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "\n",
        "topology_understanding_time_calc_file_address = f\"/content/topology_understanding_time_Run{run_number}.csv\"\n",
        "if os.path.isfile(topology_understanding_time_calc_file_address):\n",
        "  topology_understanding_time_df = pd.read_csv(topology_understanding_time_calc_file_address)\n",
        "else:\n",
        "  topology_understanding_time_df = pd.DataFrame(columns=[\"Scenario\",\"Visualization\",\"Diagram_Type\",\"Run\",\"Time\"])\n",
        "\n",
        "model_name2 = \"gpt-4-turbo\"\n",
        "temp = 1.0\n",
        "diagram_types = [\"Messy_Layout\", \"No_Labels_On_Edges\", \"Normal\"]\n",
        "visualization_formats =[\"GNS3\",\"Paper_Sketches\",\"PowerPoint\"]\n",
        "\n",
        "#--------------------------------------------------------------------------------\n",
        "\n",
        "genet_dataset_dir = \"/content/GeNet-Framework/Dataset\"\n",
        "topology_understanding_output_dir = \"/content/topology_understanding_output\"\n",
        "os.makedirs(topology_understanding_output_dir, exist_ok=True)\n",
        "scenarios = {\n",
        "    \"Configuration Scenarios\": [\"Role_Based_CLI_Access\",\"Time_Based_Access_List\",\"Transparent_IOS_Firewall\", \"Basic_Zone_Based_Firewall\", \"IP_Traffic_Export\"],\n",
        "    \"Topology Scenarios\": [\"Adding_Communication_Servers\", \"Adding_DMZ\", \"Adding_DRA\", \"Adding_Local_PCs\", \"Internet_Connectivity\"]\n",
        "            }\n",
        "input_text =\"\"\"As a network topology analyst, provide a detailed description of the components and edges in the given diagram.\n",
        "Ensure the description includes: (1) the specific icon of each component (if icons are present), such as router, pc, firewall, etc. (2) a detailed list of all edges with both edge interfaces described if edge labels are present.\n",
        "Avoid adding any extra comments or interpretations about the diagram.\"\"\"\n",
        "\n",
        "for scenario_type, scenario_list in scenarios.items():\n",
        "  topology_image_variance_dir = os.payh.join(genet_dataset_dir, scenario_type, \"Topology_image_variance\")\n",
        "  result_scenario_type_dir = os.path.join(topology_understanding_output_dir, scenario_type)\n",
        "  os.makedirs(result_scenario_type_dir, exist_ok=True)\n",
        "\n",
        "  for visualization in visualization_formats:\n",
        "    visualization_format_dir = os.path.join(topology_image_variance_dir, visualization)\n",
        "    result_visualization_dir = os.path.join(result_scenario_type_dir, visualization)\n",
        "    os.makedirs(result_visualization_dir, exist_ok=True)\n",
        "  for diagram_type in diagram_types:\n",
        "    diagram_type_dir_path = os.path.join(visualization_format_dir, diagram_type)\n",
        "    result_diagram_type_dir = os.path.join(result_visualization_dir, diagram_type)\n",
        "    os.makedirs(result_diagram_type_dir, exist_ok=True)\n",
        "    for scenario in scenario_list:\n",
        "\n",
        "      scenario_dir = os.path.join(diagram_type_dir_path, scenario)\n",
        "      result_scenario_dir = os.path.join(result_diagram_type_dir, scenario)\n",
        "      os.makedirs(result_scenario_dir, exist_ok=True)\n",
        "      graph_image_path = f\"{scenario_dir}/{scenario}_{visualization}_{diagram_type}.jpg\"\n",
        "      img_content = create_image_content(graph_image_path)\n",
        "      ans_file_path = os.path.join(result_scenario_dir,f\"Topology(Run{run_number}).txt\")\n",
        "      if os.path.isfile(ans_file_path):\n",
        "        continue\n",
        "      print(f\"\\n--------------VISUALIZATION: {visualization}, DIAGRAM TYPE: {diagram_type}, SCENARIO: {scenario}, RUN:{run_number} ----------------------------------\\n\")\n",
        "      start_time = time.time()\n",
        "      gpt_answer = make_request(model_name=model_name2, input_text=input_text, temperature=temp, image_content=img_content, image_path=graph_image_path, max_tokens=2048).json()\n",
        "      answer = gpt_answer[\"choices\"][0]\n",
        "      end_time = time.time()\n",
        "      time_taken = end_time-start_time\n",
        "      new_row = {\"Scenario\":scenario, \"Visualization\":visualization, \"Diagram_Type\":diagram_type, \"Run\":run_number, \"Time\":time_taken}\n",
        "      topology_understanding_time_df.loc[len(topology_understanding_time_df)] = new_row\n",
        "      ans_file_path = os.path.join(result_scenario_dir,f\"Topology(Run{run_number}).txt\")\n",
        "      text_file = open(ans_file_path, \"w\")\n",
        "      text_file.write(answer['message']['content'])\n",
        "      text_file.close()\n",
        "      print(answer['message']['content'])\n",
        "topology_understanding_time_df.to_csv(topology_understanding_time_calc_file_address, index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2DVf-YQTUI6"
      },
      "source": [
        "## Intent Implementation Module"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The instructions for the Intent Implementation Assistant:**\n",
        "> You are a network architecture and configuration expert.\n",
        "You are given 2 files and an intent by a user, one of the given files contains a textual representation of the network topology, and the other contains the configurations of the network devices.\n",
        "Given the files and an intent, your mission is to modify those files so that the network adheres to the user intent.\n",
        "If a change to the topology is required, please update the file of the textual representation of the topology accordingly. If the change is an addition of a network component, please configure it and add the configuration to the configurations file.\n",
        "After modifying a file, you provide the user a way to access the updated file to download it.\n",
        "In your answer to the user, you should provide brief explanations of the actions, changes, and updates you perform.\n",
        "If at any point in your messaging thread you do not have access to all the given files, state this and stop answering."
      ],
      "metadata": {
        "id": "qLu0SrQsnVXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intent_implementation_assistant_instructions = \"\"\"You are a network architecture and configuration expert.\n",
        "You are given 2 files and an intent by a user, one of the given files contains a textual representation of the network topology, and the other contains the configurations of the network devices.\n",
        "Given the files and an intent, your mission is to modify those files so that the network adheres to the user intent.\n",
        "If a change to the topology is required, please update the file of the textual representation of the topology accordingly. If the change is an addition of a network component, please configure it and add the configuration to the configurations file.\n",
        "After modifying a file, you provide the user a way to access the updated file to download it.\n",
        "In your answer to the user, you should provide brief explanations of the actions, changes, and updates you perform.\n",
        "If at any point in your messaging thread you do not have access to all the given files, state this and stop answering.\"\"\""
      ],
      "metadata": {
        "id": "lOSAvtq0nmjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_assistant = client.beta.assistants.create(\n",
        "    instructions= intent_implementation_assistant_instructions,\n",
        "    name=\"Network Architecture Expert\",\n",
        "    tools=[{\"type\": \"code_interpreter\"}, {\"type\": \"file_search\"}],\n",
        "    model=\"gpt-4-turbo\",\n",
        ")\n",
        "assist_num = my_assistant.id\n",
        "print(my_assistant)"
      ],
      "metadata": {
        "id": "aviWHIFKn612"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The prompt for this task:**\n",
        "> Hello network architecture expert, Here you were given two text files: a full configuration file named “{configuration_file_name}” and a textual representation of the topology named “{textual_topology_name}” Here is my intent: {intent}. Please ensure that you read both of the provided files entirely and make the necessary modifications accordingly, apply the modifications without waiting for confirmation for your actions.\n",
        "        "
      ],
      "metadata": {
        "id": "RmmMF6SSgI_l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCN8QyeaThY8"
      },
      "outputs": [],
      "source": [
        "def create_thread(number, intent, textual_pr_file, config_file):\n",
        "\n",
        "  configuration_file_name = \"Total_Configs.txt\"\n",
        "  textual_topology_name = f'Topology(Run{number}).txt'\n",
        "\n",
        "\n",
        "  message_thread = client.beta.threads.create(\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f'Hello network architecture expert, Here you were given two text files: a full configuration file named “{configuration_file_name}” and a textual representation of the topology named “{textual_topology_name}” Here is my intent: {intent}. Please ensure that you read both of the provided files entirely and make the necessary modifications accordingly, apply the modifications without waiting for confirmation for your actions.',\n",
        "        #----------------- ADDITIONAL LINES FOR NEW API CODE-----------------------------\n",
        "        \"attachments\": [\n",
        "        {\"file_id\": config_file.id, \"tools\": [{\"type\": \"file_search\"},{\"type\": \"code_interpreter\"}]},\n",
        "        {\"file_id\": textual_pr_file.id, \"tools\": [{\"type\": \"file_search\"},{\"type\": \"code_interpreter\"}]}\n",
        "        ],\n",
        "        #-----------------------------------------------------------------------------------\n",
        "      },\n",
        "    ]\n",
        "  )\n",
        "  return message_thread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8T-t5GUas9Jf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import os.path\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "intent_implementation_time_calc_file_address = f\"/content/Intent_implementation_time_run{run_number}.csv\"\n",
        "if os.path.isfile(intent_implementation_time_calc_file_address):\n",
        "  intent_implementation_time_df = pd.read_csv(intent_implementation_time_calc_file_address)\n",
        "else:\n",
        "  intent_implementation_time_df = pd.DataFrame(columns=[\"Scenario\",\"Visualization\",\"Diagram_Type\" \"Run\",\"Time\"])\n",
        "\n",
        "scenarios = {\n",
        "    \"Configuration Scenarios\": [\"Role_Based_CLI_Access\",\"Time_Based_Access_List\",\"Transparent_IOS_Firewall\", \"Basic_Zone_Based_Firewall\", \"IP_Traffic_Export\"],\n",
        "    \"Topology Scenarios\": [\"Adding_Communication_Servers\", \"Adding_DMZ\", \"Adding_DRA\", \"Adding_Local_PCs\", \"Internet_Connectivity\"]\n",
        "            }\n",
        "topology_understanding_output_dir = \"/content/topology_understanding_output\"\n",
        "intent_implementation_output_dir = \"/content/intent_implementation_results\"\n",
        "genet_dataset_dir = \"/content/GeNet-Framework/Dataset\"\n",
        "\n",
        "def intent_implementation_execution(row):\n",
        "\n",
        "  if row[\"Intent_Implementation\"] == \"V\":\n",
        "    return row\n",
        "  visualization = row[\"Visualization\"]\n",
        "  diagram_type = row[\"Diagram_Type\"]\n",
        "  scenario = row[\"Scenario\"]\n",
        "  scenario_type = row[\"Scenario_Type\"]\n",
        "  visualization_dir = os.path.join(intent_implementation_output_dir, scenario_type, visualization)\n",
        "  diagram_type_dir = os.path.join(visualization_dir, diagram_type)\n",
        "  intent_path = os.path.join(genet_dataset_dir, scenario_type, \"Initial files\", scenario, \"intent.txt\")\n",
        "  config_path = os.path.join(genet_dataset_dir, scenario_type, \"Initial files\", scenario, \"Total_Configs.txt\")\n",
        "  intent = open(intent_path, 'r').read()\n",
        "  scenario_folder = os.path.join(diagram_type_dir, scenario)\n",
        "  os.makedirs(scenario_folder, exist_ok=True)\n",
        "  print(f\"\\n---------------------[VISUALIZATION: {visualization}, DIAGRAM TYPE: {diagram_type}, SCENARIO: {scenario}, RUN:{run_number}]--------------\\n\")\n",
        "\n",
        "  # upload the configuration file to openAI\n",
        "  config_file = client.files.create(\n",
        "    file=open(config_path, \"rb\"),\n",
        "    purpose='assistants'\n",
        "    )\n",
        "\n",
        "  run_folder = os.path.join(scenario_folder, f\"Run{run_number}\")\n",
        "  os.makedirs(run_folder, exist_ok=True)\n",
        "  # upload the topology understanding result file to openAI\n",
        "  topology_file = f\"{topology_understanding_output_dir}/{visualization}/{diagram_type}/{scenario}/Topology(Run{run_number}).txt\"\n",
        "  textual_pr_file = client.files.create(\n",
        "    file=open(topology_file, \"rb\"),\n",
        "    purpose='assistants'\n",
        "  )\n",
        "  # create a new thread in the assistant\n",
        "  message_thread = create_thread(run_number, intent, textual_pr_file, config_file)\n",
        "  thread_id = message_thread.id\n",
        "\n",
        "  # run the thread\n",
        "  start_time = time.time()\n",
        "  run = client.beta.threads.runs.create_and_poll(\n",
        "    temperature = 1.0,\n",
        "    thread_id = thread_id,\n",
        "    assistant_id = assist_num\n",
        "  )\n",
        "\n",
        "  # check if the run is completed\n",
        "  if run.status == 'completed':\n",
        "    end_time = time.time()\n",
        "    time_taken = end_time-start_time\n",
        "\n",
        "    messages = client.beta.threads.messages.list(\n",
        "    thread_id=thread_id\n",
        "    )\n",
        "\n",
        "    #getting the run results attachments:\n",
        "    attachments =[]\n",
        "    for message in messages.data:\n",
        "      if message.role == \"assistant\":\n",
        "        messg_id = message.id\n",
        "        value = message.content[0].text.value\n",
        "        print(value)\n",
        "\n",
        "        if message.attachments:\n",
        "            for attachment in message.attachments:\n",
        "                file = client.files.retrieve(attachment.file_id)\n",
        "                if file.purpose == \"assistants_output\":\n",
        "                    content = client.files.content(file.id)\n",
        "                    file_name = file.filename\n",
        "                    # removing extra edditions from the generated file\n",
        "                    new_file_name = file_name.rsplit('/')[-1]\n",
        "                    new_file_name = new_file_name\n",
        "                    with open(f\"{run_folder}/{new_file_name}\", \"wb\") as f:\n",
        "                        f.write(content.read())\n",
        "                    attachments.append(new_file_name)\n",
        "    print(\"\\n\\n\")\n",
        "    if attachments:\n",
        "      for name in attachments:\n",
        "        print(f\"downloaded file named {name}\\n\")\n",
        "      row[\"Intent_Implementation\"] = \"V\"\n",
        "    else:\n",
        "      print(\"ERROR: Attachments not found \\n\")\n",
        "    new_row = {\"Scenario_Type\": scenario_type ,\"Scenario\":scenario, \"Visualization\":visualization, \"Diagram_Type\":diagram_type,\"Run\":run_number, \"Time\":time_taken}\n",
        "\n",
        "    intent_implementation_time_df.loc[len(intent_implementation_time_df)] = new_row\n",
        "\n",
        "  # in case the run crashed for some reason:\n",
        "  else:\n",
        "    print(f\"Run {run_number} failed with status {run.status}\")\n",
        "    new_row = {\"Scenario_Type\": scenario_type ,\"Scenario\":scenario, \"Visualization\":visualization, \"Diagram_Type\":diagram_type, \"Run\":run_number, \"Time\":0}\n",
        "    intent_implementation_time_df.loc[len(intent_implementation_time_df)] = new_row\n",
        "    row[\"Intent_Implementation\"] = \"X\"\n",
        "  print(\"\\n---------------------------------------------------------\\n\")\n",
        "\n",
        "  time.sleep(5)\n",
        "\n",
        "  intent_implementation_time_df.to_csv(intent_implementation_time_calc_file_address, index=False)\n",
        "  return row\n",
        "\n",
        "\n",
        "if not os.path.isfile(f\"/content/Run{run_number}_tracking.csv\"):\n",
        "  df = pd.read_csv(\"/content/Dataset/specs/GeNet_result_template.csv\")\n",
        "else:\n",
        "  df = pd.read_csv(f\"/content/Run{run_number}_tracking.csv\")\n",
        "\n",
        "df_dict = df.to_dict('index')\n",
        "for index, row in df_dict.items():\n",
        "  row = intent_implementation_execution(row)\n",
        "df = pd.DataFrame.from_dict(df_dict, orient='index')\n",
        "csv_file_path = f\"/content/Intent_implementation_time_run{run_number}.csv\" # Specify the desired file path\n",
        "df.to_csv(csv_file_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdKDK8aoqkV8"
      },
      "source": [
        "## Topology Understanding text to json and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrwuBfOtqj9X"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "def parse_topology_from_response(natural_language_response):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4-turbo\",\n",
        "        response_format={ \"type\": \"json_object\" },\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"\n",
        "                You will recieve a textual description of a network topology. Convert it to a JSON format as follows:\n",
        "                {\n",
        "                  \"nodes\": [\n",
        "                    {\"label\":<NODE1>,\n",
        "                     \"icon\": <the respective icon, one of [router, firewall, ethernet_switch, pc, cloud, ids]>\n",
        "                     //Notice! If needed, you should change the icon name to one of the options above, for example \"Desktop computer symbol\" should change to \"pc\".\n",
        "                    },\n",
        "                    ...\n",
        "                    ] // This is a list of all the device names mentioned in the topology(routers, firewalls, switches, pc, etc)\n",
        "                     \"links\": [[<source_device>, <destination_device>, <source_network_interface>, <destination_network_interface>],...] // This is a list of all the connections/edges mentioned in the topology, each connection represented as an array\n",
        "               }\n",
        "               Notice! if no interfaces are mentioned in the textual description please leave an empty string (\"\") in the <source_network_interface>, <destination_network_interface> fields\n",
        "                 \"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"{natural_language_response}\"\n",
        "\n",
        "            }\n",
        "        ],\n",
        "        temperature = 0.2, #setting the temperature to a higher than zero value so the LLM can handle more complex textual description\n",
        "        top_p = 0.1\n",
        "    )\n",
        "\n",
        "    return json.loads(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDx1gSjRq6Ft"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"/content/topology_understanding_result_parsed_to_json\", exist_ok=True)\n",
        "parsing_dir_path = \"/content/topology_understanding_result_parsed_to_json\"\n",
        "\n",
        "\n",
        "\n",
        "def topology_understanding_eval_function(row):\n",
        "  if row[\"Topology_Understanding_Eval\"] == \"V\":\n",
        "    return row\n",
        "  visualization = row[\"Visualization\"]\n",
        "  diagram_type = row[\"Diagram_Type\"]\n",
        "  scenario = row[\"Scenario\"]\n",
        "  scenario_type = row[\"Scenario_Type\"]\n",
        "  visualization_diagram_dir = os.path.join(topology_understanding_output_dir, visualization)\n",
        "  diagram_type_dir = os.path.join(visualization_diagram_dir, diagram_type)\n",
        "  scenario_dir = os.path.join(diagram_type_dir, scenario)\n",
        "  topology_text_file = f\"{topology_understanding_output_dir}/{scenario_type}/{visualization}/{diagram_type}/{scenario}/Topology(Run{run_number}).txt\"\n",
        "  file_path = Path(topology_text_file)\n",
        "  output_file_path = f\"{parsing_dir_path}/{scenario_type}/{visualization}/{diagram_type}/{scenario}/Parsed_Topology(Run{run_number}).json\"\n",
        "  if os.path.isfile(output_file_path):\n",
        "    print(f\"{visualization}_{diagram_type}_{scenario} : {run_number} done. \\n\")\n",
        "    row[\"Topology_Understanding_Eval\"] = \"V\"\n",
        "    return row\n",
        "  file_content = file_path.read_text()\n",
        "  parsed_topology = parse_topology_from_response(file_content)\n",
        "  with open(output_file_path, 'w', encoding='utf-8') as f:\n",
        "      json.dump(parsed_topology, f, ensure_ascii=False, indent=4)\n",
        "  print(f\"{visualization}_{diagram_type}_{scenario} : {run_number} done. \\n\")\n",
        "\n",
        "\n",
        "df = pd.read_csv(f\"/content/Run{run_number}_tracking.csv\")\n",
        "df_dict = df.to_dict('index')\n",
        "for index, row in df_dict.items():\n",
        "  row = topology_understanding_eval_function(row)\n",
        "df = pd.DataFrame.from_dict(df_dict, orient='index')\n",
        "csv_file_path = f\"/content/Run{run_number}_tracking.csv\" # Specify the desired file path\n",
        "df.to_csv(csv_file_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tZE9DeRrhxb"
      },
      "source": [
        "### Running comparison between Topology Understanding results and Ground truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXRk5R8Svog2"
      },
      "outputs": [],
      "source": [
        "from itertools import permutations, combinations\n",
        "\n",
        "def get_equal_pairs(arr1, arr2, attr=\"label\"):\n",
        "    equals = []\n",
        "\n",
        "    # For each product set {i,j}|i!=j , add to array if strings are identical\n",
        "    for i in range(0,len(arr1)):\n",
        "        for j in range(0, len(arr2)):\n",
        "            if arr1[i][attr].lower() == arr2[j][attr].lower():\n",
        "              equals = equals + [(arr1[i], arr2[j])]\n",
        "\n",
        "    return equals\n",
        "\n",
        "def get_sim_NPL(nodes1, nodes2):\n",
        "    sim_NPL = get_equal_pairs(arr1 = nodes1, arr2 = nodes2, attr=\"label\")\n",
        "    return sim_NPL\n",
        "\n",
        "#def get_sim_NPI(nodes1, nodes2, sim_NPL):\n",
        "def get_sim_NPI(sim_NPL):\n",
        "    sim_NPI = []\n",
        "    for pair in sim_NPL:\n",
        "        node1 = pair[0]\n",
        "        node2 = pair[1]\n",
        "        if  node1[\"icon\"].lower() == node2[\"icon\"].lower():\n",
        "          sim_NPI = sim_NPI + [pair]\n",
        "\n",
        "    return sim_NPI\n",
        "\n",
        "def are_connected(node1, node2, links):\n",
        "    undirected_links = [set([link[0], link[1]]) for link in links]\n",
        "    query_link = set([node1[\"label\"], node2[\"label\"]])\n",
        "    if query_link in undirected_links:\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def get_edge(node1, node2, links):\n",
        "    node1_label = node1[\"label\"]\n",
        "    node2_label = node2[\"label\"]\n",
        "    possible_links = [link for link in links if set([node1_label, node2_label]) == set([link[0], link[1]])]\n",
        "    link = possible_links[0]\n",
        "\n",
        "    return link\n",
        "\n",
        "def get_sim_E(sim_NPL, links1, links2):\n",
        "    sim_E = 0\n",
        "    sim_NPL_pairs = combinations(sim_NPL, 2)\n",
        "    for sim_NPL_pair in sim_NPL_pairs:\n",
        "        sim_pair1 = sim_NPL_pair[0]\n",
        "        sim_pair2 = sim_NPL_pair[1]\n",
        "        if are_connected(sim_pair1[0], sim_pair2[0], links=links1) and are_connected(sim_pair1[1], sim_pair2[1], links=links2):\n",
        "            sim_E = sim_E + 1\n",
        "\n",
        "    return sim_E\n",
        "\n",
        "def get_sim_EPlabel(sim_NPL, links1, links2):\n",
        "    sim_EPlabel = 0\n",
        "    sim_NPL_pairs = combinations(sim_NPL, 2)\n",
        "    for sim_NPL_pair in sim_NPL_pairs:\n",
        "        sim_pair1 = sim_NPL_pair[0]\n",
        "        sim_pair2 = sim_NPL_pair[1]\n",
        "        connected_by_edge = are_connected(sim_pair1[0], sim_pair2[0], links=links1) and are_connected(sim_pair1[1], sim_pair2[1], links=links2)\n",
        "        if connected_by_edge:\n",
        "            edge1 = get_edge(sim_pair1[0], sim_pair2[0], links1)\n",
        "            edge2 = get_edge(sim_pair1[1], sim_pair2[1], links2)\n",
        "            edge1_interfaces = sorted([str(edge1[2]),str(edge1[3])])\n",
        "            edge2_interfaces = sorted([str(edge2[2]), str(edge2[3])])\n",
        "            if edge1_interfaces[0].lower() == edge2_interfaces[0].lower():\n",
        "                sim_EPlabel = sim_EPlabel + 1\n",
        "            if edge1_interfaces[1].lower() == edge2_interfaces[1].lower():\n",
        "                sim_EPlabel = sim_EPlabel + 1\n",
        "\n",
        "    return sim_EPlabel\n",
        "\n",
        "def total_nodes(topology):\n",
        "    return len(topology[\"nodes\"])\n",
        "\n",
        "def total_edges(topology):\n",
        "    return len(topology[\"links\"])\n",
        "\n",
        "\n",
        "# strip labels spaces\n",
        "def strip_node_names(nodes):\n",
        "  for node in nodes:\n",
        "    node[\"label\"] = node[\"label\"].replace(\" \",\"\")\n",
        "  return nodes\n",
        "\n",
        "#strip edges spaces\n",
        "def strip_edge_names(links):\n",
        "  for link in links:\n",
        "    link[0] = link[0].replace(\" \",\"\")\n",
        "    link[1] = link[1].replace(\" \",\"\")\n",
        "  return links\n",
        "\n",
        "\n",
        "def get_comparison_metrics(topology1, topology2):\n",
        "    N_coe = 0.3\n",
        "    NPL_coe =0.2\n",
        "    NPI_coe = 0.05\n",
        "    E_coe = 0.35\n",
        "    EPlabel_coe = 0.1\n",
        "\n",
        "    # remove spaces in names\n",
        "    topology1[\"nodes\"] = strip_node_names(topology1[\"nodes\"])\n",
        "    topology2[\"nodes\"] = strip_node_names(topology2[\"nodes\"])\n",
        "    topology1[\"links\"] = strip_edge_names(topology1[\"links\"])\n",
        "    topology2[\"links\"] = strip_edge_names(topology2[\"links\"])\n",
        "\n",
        "    N1, N2 = total_nodes(topology1), total_nodes(topology2)\n",
        "    if N1 == 0 or N2 == 0:\n",
        "        raise Exception(\"N1 or N2 is 0, Cannot divide by 0\")\n",
        "\n",
        "    E1, E2 = total_edges(topology1), total_edges(topology2)\n",
        "    if E1 == 0 or E2 == 0:\n",
        "        raise Exception(\"E1 or E2 is 0, Cannot divide by 0\")\n",
        "\n",
        "    sim_NPL = get_sim_NPL(topology1[\"nodes\"], topology2[\"nodes\"])\n",
        "    NPL = len(sim_NPL) / max(N1, N2)\n",
        "    sim_E = get_sim_E(sim_NPL, topology1[\"links\"], topology2[\"links\"])\n",
        "    sim_NPI = get_sim_NPI(sim_NPL=sim_NPL)\n",
        "    NPI = len(sim_NPI) / max(N1, N2)\n",
        "    sim_EPlabel = get_sim_EPlabel(sim_NPL, topology1[\"links\"], topology2[\"links\"])\n",
        "\n",
        "    Metric_results_value = N_coe*min(N1,N2)/max(N1,N2) + NPL_coe*NPL + NPI_coe*NPI + E_coe*sim_E/max(E1,E2) + EPlabel_coe*sim_EPlabel/(2*max(E1,E2))\n",
        "    return {'N1':N1, 'N2':N2, 'E1':E1, 'E2':E2, 'NPL':NPL, 'NPI':NPI, 'sim_E':sim_E, 'sim_EPlabel':sim_EPlabel, 'Metric_score':Metric_results_value}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMV2Lhg7v0_F"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "parsing_dir_path = \"/content/topology_understanding_result_parsed_to_json\"\n",
        "diagram_types = [\"Messy_Layout\", \"No_Labels_On_Edges\", \"Normal\"]\n",
        "visualization_formats =[\"GNS3\",  \"Paper_Sketches\", \"PowerPoint\"] #\"Packet_Tracer\", \"Visio\"\n",
        "scenarios = {\n",
        "    \"Configuration Scenarios\": [\"Role_Based_CLI_Access\",\"Time_Based_Access_List\",\"Transparent_IOS_Firewall\", \"Basic_Zone_Based_Firewall\", \"IP_Traffic_Export\"],\n",
        "    \"Topology Scenarios\": [\"Adding_Communication_Servers\", \"Adding_DMZ\", \"Adding_DRA\", \"Adding_Local_PCs\", \"Internet_Connectivity\"]\n",
        "            }\n",
        "temp = 1.0\n",
        "results_list = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for scenario_type, scenario_list in scenarios.items():\n",
        "  for visualization in visualization_formats:\n",
        "    for diagram_type in diagram_types:\n",
        "      for scenario in scenario_list:\n",
        "\n",
        "        gns3_file_path = f\"/content/GeNet-Framework/Dataset/{scenario_type}/gns3_topology_parsing/{scenario}.json\"\n",
        "        with open(gns3_file_path, 'r') as f:\n",
        "          benchmark_topology = json.load(f)\n",
        "        topology_understanding_scenario_directory = f\"{parsing_dir_path}/{scenario_type}/{visualization}/{diagram_type}/{scenario}\"\n",
        "\n",
        "        print(f\"Running {visualization} {diagram_type} {scenario} {run_number} \\n\")\n",
        "        with open(f\"{topology_understanding_scenario_directory}/Parsed_Topology(Run{run_number}).json\", 'r') as f:\n",
        "          openai_topology = json.load(f)\n",
        "        result = get_comparison_metrics(benchmark_topology, openai_topology)\n",
        "        result[\"Scenario_Type\"] = scenario_type\n",
        "        result[\"Scenario\"] = scenario\n",
        "        result[\"Visualization\"] = visualization\n",
        "        result[\"Diagram_Type\"] = diagram_type\n",
        "        result[\"Run\"] = run_number\n",
        "\n",
        "        results_list.append(result)\n",
        "        pprint.pprint(result)\n",
        "        print(\"--------------------------\\n\")\n",
        "\n",
        "\n",
        "with open(f\"/{parsing_dir_path}/Topology_Understanding_Run{run_number}_evaluation_results.json\", \"w\") as f:\n",
        "  json.dump(results_list, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "df = pd.DataFrame(results_list)\n",
        "df.to_csv(f\"/{parsing_dir_path}/Topology_Understanding_Run{run_number}_evaluation_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfErlY2V9Hps"
      },
      "source": [
        "## Intent Implementation Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBOEBYny9Nrf"
      },
      "source": [
        "### Evaluation:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instructions for LLM-Based Evaluation Assistant:**\n",
        ">You are a helpful networking intent implementation evaluator assistant. Your role as an evaluator is to assess the accuracy of network intent implementation by grading it. You will review the provided files:  \n",
        "1. Initial Network Components Configuration – The starting configuration of network devices.  \n",
        "2. Initial Topology Description – The original structure of the network.  \n",
        "3. Textual Intent – A detailed description of the desired changes or outcomes for the network's configuration.  \n",
        "4. Updated Network Components Configuration files or topology files – Several files which show the changes made to the topology or to the configuration based on the intent. The number of those files can be one or more.\n",
        "\n",
        ">Evaluation Process:\n",
        "1. Understand the Intent: Carefully analyze the textual intent to fully grasp the desired changes or outcomes.  \n",
        "2. Analyze Initial Files: Examine the initial network configuration and topology to understand the starting state and context.  \n",
        "3. Evaluate Updated Files: Compare the updated configurations against the intent to determine if the desired changes have been accurately implemented.  \n",
        "\n",
        ">Scoring and Grading:  \n",
        "- Scoring Keys: You will be provided with specific scoring keys by the user to guide your evaluation. Each of those keys specifies a condition for noncompliance with the intent implementation, and the point deductions for this specific noncompliance.\n",
        "\t- Points should only be deducted if the updated file complies with the key’s condition (i.e., if the issue described in the key is present in the implementation).\n",
        "\t- Partial deductions are allowed for partial compliance or minor issues related to a key.  \n",
        "- Grading:  \n",
        "\t- Start with a grade of 100.\n",
        "\t- If the implementation meets the noncompliance criteria described in a key, subtract the corresponding points from the grade.\n",
        "\t- Ensure deductions align strictly with the provided scoring keys and do not penalize issues outside their scope.  \n",
        "\n",
        ">Response Guidelines:  \n",
        "- Provide the final grade as a numeric value (0–100).  \n",
        "- Adhere strictly to these instructions and the provided scoring keys during the evaluation process.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XLp5tsxqkj2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "implementation_evaluator_assistant_instructions = \"\"\"You are a helpful networking intent implementation evaluator assistant. Your role as an evaluator is to assess the accuracy of network intent implementation by grading it. You will review the provided files:\n",
        "1. Initial Network Components Configuration – The starting configuration of network devices.\n",
        "2. Initial Topology Description – The original structure of the network.\n",
        "3. Textual Intent – A detailed description of the desired changes or outcomes for the network's configuration.\n",
        "4. Updated Network Components Configuration files or topology files – Several files which show the changes made to the topology or to the configuration based on the intent. The number of those files can be one or more.\n",
        "\n",
        "Evaluation Process:\n",
        "1. Understand the Intent: Carefully analyze the textual intent to fully grasp the desired changes or outcomes.\n",
        "2. Analyze Initial Files: Examine the initial network configuration and topology to understand the starting state and context.\n",
        "3. Evaluate Updated Files: Compare the updated configurations against the intent to determine if the desired changes have been accurately implemented.\n",
        "\n",
        "Scoring and Grading:\n",
        "- Scoring Keys: You will be provided with specific scoring keys by the user to guide your evaluation. Each of those keys specifies a condition for noncompliance with the intent implementation, and the point deductions for this specific noncompliance.\n",
        "\t- Points should only be deducted if the updated file complies with the key’s condition (i.e., if the issue described in the key is present in the implementation).\n",
        "\t- Partial deductions are allowed for partial compliance or minor issues related to a key.\n",
        "- Grading:\n",
        "\t- Start with a grade of 100.\n",
        "\t- If the implementation meets the noncompliance criteria described in a key, subtract the corresponding points from the grade.\n",
        "\t- Ensure deductions align strictly with the provided scoring keys and do not penalize issues outside their scope.\n",
        "\n",
        "Response Guidelines:\n",
        "- Provide the final grade as a numeric value (0–100).\n",
        "- Adhere strictly to these instructions and the provided scoring keys during the evaluation process.\"\"\""
      ],
      "metadata": {
        "id": "SSwwJDpHllYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_assistant = client.beta.assistants.create(\n",
        "    instructions=implementation_evaluator_assistant_instructions,\n",
        "    name=\"Networking Intent Implementation Evaluator\",\n",
        "    tools=[{\"type\": \"file_search\"}],\n",
        "    model=\"gpt-4o\",\n",
        "    temperature = 0.1\n",
        ")\n",
        "assist_num = my_assistant.id\n",
        "print(my_assistant)"
      ],
      "metadata": {
        "id": "qPxFVckaleiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The prompt for this task:**\n",
        "> Hello Networking Intent Implementation Evaluator, I added here {file_number} files: '{input_configuration_file_name}' which is the initial network component configuration file, '{input_textual_topology_name}' which is the initial topology description, an intent file named 'intent.txt', and {len(files)} updated files which shows the changes after intent implementation named {files_names}.\n",
        "Here are the scoring keys for your evaluation:\n",
        "{scoring_keys}\n",
        "Given the these files, and the scoring keys, assign a grade to the intent implementation according to your instructions, and briefly explain your scoring for each key.,\n"
      ],
      "metadata": {
        "id": "mIaHeQRPgp64"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7hT3qoa9dq6"
      },
      "outputs": [],
      "source": [
        "def create_thread_topology_scenario(intent, input_config, input_topology, input_topology_name, updated_files_path, scoring_keys_address):\n",
        "\n",
        "  input_configuration_file_name = 'Total_Configs.txt'\n",
        "  input_textual_topology_name = f'{input_topology_name}.json'\n",
        "\n",
        "  files = [f for f in os.listdir(updated_files_path) if os.path.isfile(os.path.join(updated_files_path, f))]\n",
        "  updated_files = []\n",
        "  for file in files:\n",
        "    file_path = os.path.join(updated_files_path, file)\n",
        "    assistant_file = client.files.create(\n",
        "      file=open(file_path, \"rb\"),\n",
        "      purpose='assistants'\n",
        "      )\n",
        "    updated_files.append((file, assistant_file.id))\n",
        "\n",
        "  input_config_file = client.files.create(\n",
        "    file=open(input_config, \"rb\"),\n",
        "    purpose='assistants'\n",
        "    )\n",
        "  input_topology_file = client.files.create(\n",
        "    file=open(input_topology, \"rb\"),\n",
        "    purpose='assistants'\n",
        "    )\n",
        "  intent_file = client.files.create(\n",
        "    file=open(intent, \"rb\"),\n",
        "    purpose='assistants'\n",
        "    )\n",
        "  with open( scoring_keys_address, 'r') as file:\n",
        "    scoring_keys = file.read()\n",
        "\n",
        "  attachments = [\n",
        "        {\"file_id\": input_config_file.id, \"tools\": [{\"type\": \"file_search\"}]},\n",
        "        {\"file_id\": input_topology_file.id, \"tools\": [{\"type\": \"file_search\"}]},\n",
        "        {\"file_id\": intent_file.id, \"tools\": [{\"type\": \"file_search\"}]}\n",
        "        ]\n",
        "  for file in updated_files:\n",
        "    attachments.append({\"file_id\": file[1], \"tools\": [{\"type\": \"file_search\"}]})\n",
        "\n",
        "  file_number = 3+len(files)\n",
        "\n",
        "  if len(files) ==1:\n",
        "    updated_file_message = f\"and an updated file which shows the changes after intent implementation named {updated_files[0][0]}\"\n",
        "  else:\n",
        "    files_names = \"\"\n",
        "    for i in range(len(files)-1):\n",
        "      files_names = files_names+f\"{updated_files[i][0]}, \"\n",
        "    files_names = files_names+f\" and {updated_files[-1][0]}\"\n",
        "    updated_file_message = f\"and {len(files)} updated files which shows the changes after intent implementation named {files_names}\"\n",
        "\n",
        "\n",
        "  message_thread = client.beta.threads.create(\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"Hello Networking Intent Implementation Evaluator, I added here {file_number} files: '{input_configuration_file_name}' which is the initial network component configuration file, '{input_textual_topology_name}' which is the initial topology description, an intent file named 'intent.txt', {updated_file_message}.\n",
        "Here are the scoring keys for your evaluation:\n",
        "{scoring_keys}\n",
        "Given the these files, and the scoring keys, assign a grade to the intent implementation according to your instructions, and briefly explain your scoring for each key.\"\"\",\n",
        "        #----------------- ADDITIONAL LINES FOR NEW API CODE-----------------------------\n",
        "        \"attachments\": attachments,\n",
        "        #-----------------------------------------------------------------------------------\n",
        "      },\n",
        "    ]\n",
        "  )\n",
        "  return message_thread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_l8QCvX9gmv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "if not os.path.isfile(f\"/content/Run{run_number}_tracking.csv\"):\n",
        "  itterations_file = pd.read_csv(\"/content/Dataset/specs/GeNet_result_template.csv\")\n",
        "else:\n",
        "  itterations_file = pd.read_csv(f\"/content/Run{run_number}_tracking.csv\")\n",
        "\n",
        "\n",
        "genet_dataset_dir = \"/content/GeNet-Framework/Dataset\"\n",
        "results_folder = \"/content/Verifier_LLM_Evaluator_with_descriptions\"\n",
        "intent_implementation_output_dir = \"/content/intent_implementation_results\"\n",
        "os.makedirs(results_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "for index, row in itterations_file.iterrows():\n",
        "  if row[\"Intent_Implementation\"] != \"V\" or row[\"Intent_Implementation_Eval\"]==\"V\": # failed run or not yet graded\n",
        "    continue\n",
        "\n",
        "  scenario_type = row[\"Scenario_Type\"]\n",
        "  visualization = row[\"Visualization\"]\n",
        "  diagram_type = row[\"Diagram_Type\"]\n",
        "  scenario = row[\"Scenario\"]\n",
        "\n",
        "  scoring_keys_directory = os.path.join(genet_dataset_dir, scenario_type, \"Scoring_Keys\")\n",
        "  output_dir_address = os.path.join(results_folder, scenario_type, visualization, diagram_type)\n",
        "  os.makedirs(output_dir_address, exist_ok=True)\n",
        "  output_file_address = os.path.join(output_dir_address, f\"Run{run_number}_results.txt\") # <--- one result file per run\n",
        "  output_file = open(output_file_address, \"a\")\n",
        "\n",
        "  intent_file_address = os.path.join(genet_dataset_dir, scenario_type, \"Initial files\", scenario, \"intent.txt\")\n",
        "  input_config_file_address = os.path.join(genet_dataset_dir, scenario_type, \"Initial files\", scenario, \"Total_Configs.txt\")\n",
        "  updated_specs_scenario_directory = os.path.join(intent_implementation_output_dir, scenario_type, visualization, diagram_type, scenario)\n",
        "  scoring_keys_address = os.path.join(scoring_keys_directory, f\"{scenario}.txt\")\n",
        "\n",
        "  updated_spec_run_directory = os.path.join(updated_specs_scenario_directory,f\"Run{run_number}\")\n",
        "  input_topology_file_address = os.path.join(genet_dataset_dir, scenario_type, \"gns3_topology_parsing\", f\"{scenario}.json\")\n",
        "\n",
        "\n",
        "  message_thread = create_thread_topology_scenario(intent_file_address, input_config_file_address, input_topology_file_address, scenario, updated_spec_run_directory, scoring_keys_address)\n",
        "  thread_id = message_thread.id\n",
        "  # run the thread\n",
        "  run = client.beta.threads.runs.create_and_poll(\n",
        "    temperature = 0,\n",
        "    thread_id = thread_id,\n",
        "    assistant_id = assist_num\n",
        "  )\n",
        "  print(f\"\\n-----------[VISUALIZATION: {visualization}, DIAGRAM TYPE: {diagram_type}, SCENARIO: {scenario}]--------------\\n\")\n",
        "  output_file.write(f\"\\n----------[VISUALIZATION: {visualization}, DIAGRAM TYPE: {diagram_type}, SCENARIO: {scenario}, RUN:{run_number}]-------------------\\n\")\n",
        "  if run.status == 'completed':\n",
        "    messages = client.beta.threads.messages.list(\n",
        "    thread_id=thread_id\n",
        "    )\n",
        "    for message in messages.data:\n",
        "      if message.role == \"assistant\":\n",
        "        messg_id = message.id\n",
        "        value = message.content[0].text.value\n",
        "        output_file.write(f\"{value}\\n\")\n",
        "        print(value)\n",
        "  output_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **NOTICE!** The grades which were received from the output of the evaluation were **manually** extracted and added to the tracking file!"
      ],
      "metadata": {
        "id": "Ax098utwx5nD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltkx0Wt6-bgy"
      },
      "source": [
        "# Tracking Execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgFd0ehP-kX6"
      },
      "source": [
        "## Topology Understanding Tracking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GNjuEsr-qQy"
      },
      "outputs": [],
      "source": [
        "from inspect import EndOfBlock\n",
        "import os.path\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "\n",
        "def topology_understanding_tracking(run_num):\n",
        "  if not os.path.isfile(f\"/content/Run{run_number}_tracking.csv\"):\n",
        "    df = pd.read_csv(\"/content/Dataset/specs/GeNet_result_template.csv\")\n",
        "  else:\n",
        "    df = pd.read_csv(f\"/content/Run{run_number}_tracking.csv\")\n",
        "  topology_understanding_output_dir = \"/content/topology_understanding_output\"\n",
        "\n",
        "  df_dict = df.to_dict('index')\n",
        "  for index, row in df_dict.items(): # Unpack the tuple into index and row_data\n",
        "    visualization = row[\"Visualization\"]\n",
        "    diagram_type = row[\"Diagram_Type\"]\n",
        "    scenario = row[\"Scenario\"]\n",
        "    scenario_type = row[\"Scenario_Type\"]\n",
        "    scenario_dir = os.path.join(topology_understanding_output_dir, scenario_type, visualization, diagram_type, scenario)\n",
        "    requested_file = f\"Topology(Run{run_num}).txt\"\n",
        "    file_path = os.path.join(scenario_dir, requested_file)\n",
        "    if os.path.isfile(file_path):\n",
        "      row[\"Topology_Understanding\"] = 'V'\n",
        "    else:\n",
        "      row[\"Topology_Understanding\"] = 'X'\n",
        "  df = pd.DataFrame.from_dict(df_dict, orient='index')\n",
        "  csv_file_path = f\"/content/Run{run_number}_tracking.csv\" # Specify the desired file path\n",
        "  df.to_csv(csv_file_path, index = False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4L5GsFGAAq_"
      },
      "outputs": [],
      "source": [
        "topology_understanding_tracking(run_number) # can be changed according to your needs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEkD8fgaHdRM"
      },
      "outputs": [],
      "source": [
        "def topology_understanding_to_json_tracking(run_num):\n",
        "  if not os.path.isfile(f\"/content/Run{run_number}_tracking.csv\"):\n",
        "    df = pd.read_csv(\"/content/Dataset/specs/GeNet_result_template.csv\")\n",
        "  else:\n",
        "    df = pd.read_csv(f\"/content/Run{run_number}_tracking.csv\")\n",
        "\n",
        "  topology_understanding_eval_output_dir = \"/content/topology_understanding_result_parsed_to_json\"\n",
        "\n",
        "  df_dict = df.to_dict('index')\n",
        "  for index, row in df_dict.items(): # Unpack the tuple into index and row_data\n",
        "    visualization = row[\"Visualization\"]\n",
        "    diagram_type = row[\"Diagram_Type\"]\n",
        "    scenario = row[\"Scenario\"]\n",
        "    scenario_type = row[\"Scenario_Type\"]\n",
        "    scenario_dir = os.path.join(topology_understanding_eval_output_dir, scenario_type, visualization, diagram_type, scenario)\n",
        "    requested_file = f\"Parsed_Topology(Run{run_num}).json\"\n",
        "    file_path = os.path.join(scenario_dir, requested_file)\n",
        "    if os.path.isfile(file_path):\n",
        "      row[\"Topology_Understanding_Eval\"] = 'V'\n",
        "    else:\n",
        "      row[\"Topology_Understanding_Eval\"] = 'X'\n",
        "      print(f\"{scenario_type} {visualization} {diagram_type} {scenario} Run{run_num} has failed\")\n",
        "  df = pd.DataFrame.from_dict(df_dict, orient='index')\n",
        "  csv_file_path = f\"/content/Run{run_number}_tracking.csv\" # Specify the desired file path\n",
        "  df.to_csv(csv_file_path, index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cYcTCxII25H"
      },
      "outputs": [],
      "source": [
        "topology_understanding_to_json_tracking(run_number)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnupTQYLI8aG"
      },
      "source": [
        "##Intent Implementation Tracking\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKsouUe76SAf"
      },
      "source": [
        "Intent Implementation tracking:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBRCcp8KI-Vj"
      },
      "outputs": [],
      "source": [
        "from inspect import EndOfBlock\n",
        "import os.path\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "\n",
        "intent_implementation_output_dir = \"/content/intent_implementation_results\"\n",
        "\n",
        "def intent_implementation_tracking(run_num):\n",
        "  if not os.path.isfile(f\"/content/Run{run_number}_tracking.csv\"):\n",
        "    df = pd.read_csv(\"/content/Dataset/specs/GeNet_result_template.csv\")\n",
        "  else:\n",
        "    df = pd.read_csv(f\"/content/Run{run_number}_tracking.csv\")\n",
        "\n",
        "  df_dict = df.to_dict('index')\n",
        "  for index, row in df_dict.items(): # Unpack the tuple into index and row_data\n",
        "    visualization = row[\"Visualization\"]\n",
        "    diagram_type = row[\"Diagram_Type\"]\n",
        "    scenario = row[\"Scenario\"]\n",
        "    scenario_type = row[\"Scenario_Type\"]\n",
        "    run_related_dir = os.path.join(intent_implementation_output_dir, scenario_type, visualization, diagram_type, scenario)\n",
        "    base_directory =os.path.join(run_related_dir, f\"Run{run_num}\")\n",
        "    if os.path.isdir(base_directory):\n",
        "      # List files in the folder\n",
        "      files = [f for f in os.listdir(base_directory) if os.path.isfile(os.path.join(base_directory, f))]\n",
        "      # Check if the folder contains exactly three files\n",
        "      if len(files) >= 1:\n",
        "        row[\"Intent_Implementation\"] = \"V\"\n",
        "      else:\n",
        "        row[\"Intent_Implementation\"] = \"X\"\n",
        "    else:\n",
        "      row[\"Intent_Implementation\"] = \"X\"\n",
        "  df = pd.DataFrame.from_dict(df_dict, orient='index')\n",
        "  csv_file_path = f\"/content/Run{run_number}_tracking.csv\" # Specify the desired file path\n",
        "  df.to_csv(csv_file_path, index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7BoQ3RzJPyX"
      },
      "outputs": [],
      "source": [
        "intent_implementation_tracking(run_number)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86_jTXgu84aN"
      },
      "source": [
        "Intent Implementation eval tracking:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6qEGqBrJR5l"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def intent_implementation_tracking(run_num):\n",
        "  if not os.path.isfile(f\"/content/Run{run_number}_tracking.csv\"):\n",
        "    df = pd.read_csv(\"/content/Dataset/specs/GeNet_result_template.csv\")\n",
        "  else:\n",
        "    df = pd.read_csv(f\"/content/Run{run_number}_tracking.csv\")\n",
        "\n",
        "  df_dict = df.to_dict('index')\n",
        "  for index, row in df_dict.items(): # Unpack the tuple into index and row_data\n",
        "    if math.isnan(row[\"Grade\"]):\n",
        "      print(str(index)+ \"is nan\")\n",
        "      row[\"Intent_Implementation_Eval\"] = 'X'\n",
        "    else:\n",
        "      row[\"Intent_Implementation_Eval\"] = 'V'\n",
        "  df = pd.DataFrame.from_dict(df_dict, orient='index')\n",
        "  csv_file_path = f\"/content/Run{run_number}_tracking.csv\" # Specify the desired file path\n",
        "  df.to_csv(csv_file_path, index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfiH7koVpvnN"
      },
      "outputs": [],
      "source": [
        "intent_implementation_tracking(run_number)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Y7vlUEZyraE-"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}